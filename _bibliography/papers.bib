@article{ICIP42928.2021.9506703,
  abbr={ICIP 2021},
  title={Two-Phase Multimodal Image Fusion Using Convolutional Neural Networks},
  author={Kusram, K. and Transue, S. and Choi, M.},
  abstract={The fusion of multiple imaging modalities presents an important contribution to machine vision, but remains an ongoing challenge due to the limitations in traditional calibration methods that perform a single, global alignment. For depth and thermal imaging devices, sensor and lens intrinsics (FOV, resolution, etc.) may vary considerably, making per-pixel fusion accuracy difficult. In this paper, we present AccuFusion, a two-phase non-linear registration method to fuse multimodal images at a per-pixel level to obtain an efficient and accurate image registration. The two phases: the Coarse Fusion Network (CFN) and Refining Fusion Network (RFN), are designed to learn a robust image-space fusion that provides a non-linear mapping for accurate alignment. By employing the refinement process, we obtain per-pixel displacements to minimize local alignment errors and observe an increase of 18% in average accuracy over global registration.},
  journal={2021 IEEE International Conference on Image Processing},
  year={2021},
  month={Sept.},
  publisher=IEEE,
  doi={10.1109/ICIP42928.2021.9506703},
  url={https://ieeexplore.ieee.org/abstract/document/9506703},
  html={https://ieeexplore.ieee.org/abstract/document/9506703},
  pdf={AccuFusion__Multi_Channel_Sensor_Data_Fusion___ICIP.pdf},
  selected={true}
}
@article{9780784483893.070,
  abbr={ASCE 2021},
  title={Roadway Contextual Risk Assessment Using Dynamic Traffic Conditions Data Obtained from Autonomous Vehicles},
  author={Bendigeri, V G., Zou, F., Ogle, J H., Kusram, K.},
  abstract={Traditional road safety assessment methodologies do not recognize the driving environment's fast-changing dynamics that influence the contextual complexity and, ultimately, its risk. This paper proposes a method to use diverse open-source sensor data (LiDAR) collected by Waymo autonomous vehicles to estimate the road environment's complexity considering dynamic traffic conditions. The proposed contextual risk factor (CRF) model estimates the driving scene's complexity using the density and proximity of the objects around the vehicle. The data was analyzed frame-by-frame, and contextual risk categories of high, medium, and low were assigned. The results revealed the objects in the scene well represent the contextual complexity. However, what the driver sees in front of them and within their forward reaction space is not directly representative of the complexity of the scene and vice versa.},
  journal={2021 ASCE International Conference on Computing in Civil Engineering},
  year={2021},
  month={Sept.},
  publisher=ASCE,
  doi={10.1061/9780784483893.070},
  url={https://ascelibrary.org/doi/abs/10.1061/9780784483893.070},
  html={https://ascelibrary.org/doi/abs/10.1061/9780784483893.070},
  selected={true}
}